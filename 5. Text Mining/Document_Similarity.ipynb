{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine\n",
    "\n",
    "## NLP: Document Similarity\n",
    "\n",
    "### Keys Concepts\n",
    "- Term Document Matrix\n",
    "- Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn for feature extraction & modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "# from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "# Iteratively read files\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# For displaying images in ipython\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14.0, 8.7)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined function to read and store bbc data from multipe folders\n",
    "def load_data(folder_names,root_path):\n",
    "    fileNames = [path + '/' + 'bbc' +'/'+ folder + '/*.txt' for path,folder in zip([root_path]*len(folder_names),\n",
    "                                                                               folder_names )]\n",
    "    doc_list = []\n",
    "    tags = folder_names\n",
    "    for docs in fileNames:\n",
    "        print(docs)\n",
    "        #print(type(docs))\n",
    "        doc = glob.glob(docs) # glob method iterates through all the text documents in a folder\n",
    "        for text in doc:\n",
    "            with open(text, encoding='latin1') as f:\n",
    "                topic = docs.split('/')[8]\n",
    "\n",
    "                lines = f.readlines()\n",
    "                heading = lines[0].strip()\n",
    "                body = ' '.join([l.strip() for l in lines[1:]])\n",
    "                doc_list.append([topic, heading, body])\n",
    "        print(\"Completed loading data from folder: %s\"%topic)\n",
    "    \n",
    "    print(\"Completed Loading entire text\")\n",
    "    \n",
    "    return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/paragpradhan/Documents/Data',\n",
       " 'Science',\n",
       " 'Course/DSB6/5.',\n",
       " 'Text',\n",
       " 'Mining']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/paragpradhan/Documents/Data Science Course/DSB6/5. Text Mining/bbc/business/*.txt\n",
      "Completed loading data from folder: business\n",
      "/Users/paragpradhan/Documents/Data Science Course/DSB6/5. Text Mining/bbc/entertainment/*.txt\n",
      "Completed loading data from folder: entertainment\n",
      "/Users/paragpradhan/Documents/Data Science Course/DSB6/5. Text Mining/bbc/politics/*.txt\n",
      "Completed loading data from folder: politics\n",
      "/Users/paragpradhan/Documents/Data Science Course/DSB6/5. Text Mining/bbc/sport/*.txt\n",
      "Completed loading data from folder: sport\n",
      "/Users/paragpradhan/Documents/Data Science Course/DSB6/5. Text Mining/bbc/tech/*.txt\n",
      "Completed loading data from folder: tech\n",
      "Completed Loading entire text\n"
     ]
    }
   ],
   "source": [
    "folder_names = ['business','entertainment','politics','sport','tech']\n",
    "docs = load_data(folder_names = folder_names, root_path = os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category                            Heading  \\\n",
      "0  business    UK economy facing 'major risks'   \n",
      "1  business  Aids and climate top Davos agenda   \n",
      "2  business   Asian quake hits European shares   \n",
      "3  business   India power shares jump on debut   \n",
      "4  business    Lacroix label bought by US firm   \n",
      "\n",
      "                                             Article  \n",
      "0   The UK manufacturing sector will continue to ...  \n",
      "1   Climate change and the fight against Aids are...  \n",
      "2   Shares in Europe's leading reinsurers and tra...  \n",
      "3   Shares in India's largest power producer, Nat...  \n",
      "4   Luxury goods group LVMH has sold its loss-mak...  \n",
      "\n",
      "Shape of data is (2225, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = pd.DataFrame(docs, columns=['Category', 'Heading', 'Article'])\n",
    "print(docs.head())\n",
    "print('\\nShape of data is {}\\n'.format(docs.shape))\n",
    "# print(docs.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Documents Similarity</h2>\n",
    "<h3>From Documents -- DTM -- Cosine Similarity</h3>\n",
    "\n",
    "HTML(\"<table><tr><td><img src=\"images/docs_to_dtm.png\" alt=\"dtm\" style=\"width:100%\"></td><td><img src=\"images/cosine.jpg\" alt=\"Forest\" style=\"width:100%\"></td></tr></table>\")\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### Important\n",
    "The cosine similarity is the cosine of the angle between two vectors.\n",
    "- Cosine Similarity can take value between 0 to 1.\n",
    "- closer to 0 means dissimilar documents\n",
    "- closer to 1 means similar documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Documents Similar to a New document : First Step to Build Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Raw text --> Parsed Text --> Document Term Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why to Use Term Frequency Inverse Document Frequency over Term Frequency\n",
    "\n",
    "- TF*IDF is an information retrieval technique that weighs a termâ€™s frequency (TF) and its inverse document frequency (IDF). Each word or term has its respective TF and IDF score. The product of the TF and IDF scores of a term is called the TF*IDF weight of that term.\n",
    "\n",
    "__Put simply, the higher the TF*IDF score (weight), the rarer the term and vice versa.__\n",
    "\n",
    "__TFidf__ - is comprised of following two components\n",
    "- __TF: Term Frequency__, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization: \n",
    "\n",
    "__TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).__\n",
    "\n",
    "__IDF: Inverse Document Frequency__, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following: \n",
    "\n",
    "__IDF(t) = log_e(Total number of documents / Number of documents with term t in it).__\n",
    "\n",
    "__TFidf__ = TF * IDF\n",
    "\n",
    "**Important**\n",
    "Higher the TFidf , more important the significance of word to that document\n",
    "\n",
    "### Important Reading Article on TFidf\n",
    "https://www.kdnuggets.com/2018/08/wtf-tf-idf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tfidf matrix: (2225, 3623)\n"
     ]
    }
   ],
   "source": [
    "vectors = vectorizer.fit_transform(docs[\"Heading\"].values)\n",
    "print(\"Shape of tfidf matrix: {}\".format(vectors.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3623 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_query = [\"World facing imminent danger across global war theaters\"]\n",
    "new_query_vector = vectorizer.transform(new_query)\n",
    "new_query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = cosine_similarity(X = vectors, Y = new_query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26626668],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       ...,\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of maximum valued similar doc: 438\n",
      "Retrieved Document Header: The 'ticking budget' facing the US\n"
     ]
    }
   ],
   "source": [
    "# Extract Index of Maximum valued similar document\n",
    "argmax = np.argmax(sim)\n",
    "print(\"Index of maximum valued similar doc: %s\"%argmax)\n",
    "print(\"Retrieved Document Header: %s\"%docs[\"Heading\"][argmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The 'ticking budget' facing the US\"]\n",
      "[\"Singer Ferguson 'facing eviction'\"]\n",
      "['Spector facing more legal action']\n",
      "[\"UK economy facing 'major risks'\"]\n",
      "['Big war games battle it out']\n",
      "['Global release for Japan hit film']\n",
      "['Bollywood draws global stars']\n",
      "['Films on war triumph at Sundance']\n",
      "[\"Global digital divide 'narrowing'\"]\n",
      "['The gaming world in 2005']\n"
     ]
    }
   ],
   "source": [
    "# To Extract Top 10 Similar Documents against the new query\n",
    "ind = np.argsort(sim,axis = 0)[::-1][:10]\n",
    "for i in ind:\n",
    "    print(docs[\"Heading\"].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_doc(new_query,raw_docs):\n",
    "    vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
    "    vectors = vectorizer.fit_transform(raw_docs[\"Article\"])\n",
    "    print(\"Shape of tfidf matrix: {}\".format(vectors.shape))\n",
    "    new_query = [new_query]\n",
    "    new_query_vector = vectorizer.transform(new_query)\n",
    "    sim = cosine_similarity(X = vectors, Y = new_query_vector)\n",
    "    ind = np.argsort(sim,axis = 0)[::-1][:10]\n",
    "    for i in ind:\n",
    "        print(docs[\"Heading\"].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newQuery = \"gaming week in UK\"\n",
    "newQuery = \"england to play australia in next ashes series\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tfidf matrix: (2225, 28980)\n",
      "['Robinson wants dual code success']\n",
      "['Wilkinson to lead England']\n",
      "['Barkley fit for match in Ireland']\n",
      "['Yachvili savours France comeback']\n",
      "['Dallaglio his own man to the end']\n",
      "['X Factor show gets second series']\n",
      "['A November to remember']\n",
      "['England given tough Sevens draw']\n",
      "['Dawson set for new Wasps contract']\n",
      "[\"O'Gara revels in Ireland victory\"]\n"
     ]
    }
   ],
   "source": [
    "retrieve_doc(new_query= newQuery  , raw_docs= docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
